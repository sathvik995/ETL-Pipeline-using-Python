{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f295b2a-1edc-4675-8636-a33b8fbcd908",
   "metadata": {},
   "source": [
    "# Data ETL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a47414cf-e1a5-4ea8-b811-fc42a399a31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "(xtrain, ytrain), (xtest, ytest) = keras.datasets.fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bc299ab-04d3-4296-bf2c-84cc5ec86542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain Shape : (60000, 28, 28)\n",
      "ytrain Shape : (60000,)\n",
      "xtest Shape : (10000, 28, 28)\n",
      "ytest Shape : (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"xtrain Shape :\", xtrain.shape)\n",
    "print(\"ytrain Shape :\", ytrain.shape)\n",
    "print(\"xtest Shape :\", xtest.shape)\n",
    "print(\"ytest Shape :\", ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d51a2cd-6b58-4ff7-ad6d-fc9028596897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "531c5abe-d08f-4719-87ea-f18f72e71082",
   "metadata": {},
   "source": [
    "## clean and transform the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f63b36-9c41-423c-9f64-483fb8f98d70",
   "metadata": {},
   "source": [
    "* we will normalize the pixel values to be between 0 and 1 and reshape the data into a 4D tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0bbfb84-a150-480c-abb3-88437e1337ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "xtrain = xtrain.astype('float32') / 255\n",
    "xtest = xtest.astype('float32') / 255\n",
    "\n",
    "xtrain = np.reshape(xtrain, (xtrain.shape[0], 28, 28, 1))\n",
    "xtest = np.reshape(xtest, (xtest.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da96901f-c8a9-4656-ad50-65edb124932c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain Shape : (60000, 28, 28, 1)\n",
      "ytrain Shape : (60000,)\n",
      "xtest Shape : (10000, 28, 28, 1)\n",
      "ytest Shape : (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"xtrain Shape :\", xtrain.shape)\n",
    "print(\"ytrain Shape :\", ytrain.shape)\n",
    "print(\"xtest Shape :\", xtest.shape)\n",
    "print(\"ytest Shape :\", ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aec891-a055-46dd-85af-a2b64b11871b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1719f34d-f21f-42a2-8db1-4d9a5a7c0c43",
   "metadata": {},
   "source": [
    "## loading the data into a database\n",
    "* We will use SQLite to create a database and load the data into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8dc30a2-b191-433b-8740-b37fca6a354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('fashion_mnist.db')\n",
    "\n",
    "conn.execute('''CREATE TABLE IF NOT EXISTS images\n",
    "             (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "             image BLOB NOT NULL,\n",
    "             label INTEGER NOT NULL);''')\n",
    "\n",
    "for i in range(xtrain.shape[0]):\n",
    "    conn.execute('INSERT INTO images (image, label) VALUES (?, ?)',\n",
    "                [sqlite3.Binary(xtrain[i]), ytrain[i]])\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "for i in range(xtest.shape[0]):\n",
    "    conn.execute('INSERT INTO images (image, label) VALUES (?, ?)',\n",
    "                [sqlite3.Binary(xtest[i]), ytest[i]])\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7991a8d-b22c-4566-8a37-f0f8fb7aaad8",
   "metadata": {},
   "source": [
    "#### In the above code:\n",
    "\n",
    "* **Import sqlite3 Library:** The first line imports the sqlite3 library, which allows us to interact with SQLite databases in Python.\n",
    "\n",
    "* **Establish Database Connection:** We create a connection to the SQLite database.\n",
    "\n",
    "* **Create a Table:** We define a new table named “images” in the database to store image data and labels.\n",
    "\n",
    "* **Insert Training Data:** We loop through the training data, adding each image and its label into the “images” table.\n",
    "\n",
    "* **Save Changes:** We use the commit() method to save the changes made to the database.\n",
    "\n",
    "* **Insert Test Data:** We loop through the test data, adding each image and its label into the “images” table.\n",
    "\n",
    "* **Save Changes Again:** We call commit() once more to save the changes made during the test data insertion.\n",
    "\n",
    "* **Close Database Connection:** Finally, we close the connection to the SQLite database to complete the operations.\n",
    "\n",
    "This is the process of building a Data ETL pipeline with Python. Our ETL pipeline extracts the Fashion MNIST dataset, transforms it as needed, and loads it into an SQLite database, allowing for convenient future access and data manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3f97b5-b986-4fcf-859d-dad427b875c6",
   "metadata": {},
   "source": [
    "## reading the data stored on the SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a060a8e-e20b-4109-9724-e2143cb601d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('fashion_mnist.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('SELECT * FROM images')\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "data = pd.read_sql_query('SELECT * FROM images', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280f41ca-b44d-4d29-b017-6b8447b4a49e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52d8e236-1562-4322-ae05-e40d038e30a0",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e381b1-74cd-4031-b396-3c812034cbfb",
   "metadata": {},
   "source": [
    "The Data ETL process involves extracting data from a source, transforming it through various processes, and then loading it into a database. ETL stands for Extract, Transform, and Load, which are the key stages of this data management approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
